# Vagas

## Tag Crowd

**Palavras para excluir**

vaga, bancos, dados, ferramentas,

conhecimento, desenvolvimento, intermediario, requisitos, analise, experiencia

com, como,porque, por que, da, dos, das, em, um, a, os, é, e, ou, outro, outros,mas, mais, também, também, uma, umas,tem, porém, porem, desde, esta, está,na, nas, no, nos, ja,j já, ha, há, quero, eu, estou, www, ao, agora, alguns, algumas, não, não, não, sim, são, são, sou, temos, ter, fazer, faço, faça, br, de, ainda, mesmo, https, estamos, somoes, tenho, minha, para, pra, meu, muito, ano, nãos, hoje, maior, principalemnte, nosso, nossos, depois, trabalhamdos, fazemos, foi, até, ate, muita, se,forma, somente, nesse, nesses, pretendo, esse, esses, essa, essas, sempre, ser, ela, ele, onde, pelo, pelos, pela, você, você, devo, dica, acaha, faria, mudaria, faz, tao, tão, algum, posso, faz, quer, existe, nossa, atraves, através, saber, seus, novos

## Engenharia de dados Junior

### Vaga 1

O que você vai fazer no seu dia a dia:

Você irá integrar a equipe de desenvolvimento de ETL e armazenamento de dados, atuando:
- No entendimento das necessidades, processos e negócio dos clientes, identificando as fontes de dados necessárias para realizar análises e calcular indicadores operacionais e de negócio
- No desenvolvimento de ETL e estruturação de bancos de dados
- Na aplicação de regras de negócio em banco de dados

O que estamos procurando na pessoa que vai fazer parte do time:

- Conhecimento em Excel e demais ferramentas do Office

- Familiaridade com bancos de dados estruturados (SQL Server, Oracle, etc)

- Familiaridade com a linguagem SQL

- Interesse em aprender ferramentas de ETL e pipeline de dados (Pentaho, Alteryx, etc)

Além disso… o que mais você pode ter?

- Familiaridade com bancos de dados não-estruturados

- Conhecimento em ferramentas de ETL e pipeline de dados

- Conhecimento em T-SQL (programação procedural)

- Conhecimento em Python

### Vaga 2

Principais desafios e responsabilidades
• Trabalhar em estreita colaboração com os Business Analysts, Data Scientists e Devs na arquitetura e definição de modelos de dados, garantindo a aplicação das melhores práticas;
• Implementar e assegurar extração de dados e resolução de problemas em modelagem, obtenção e tratamento de dados;
• Ser o guardião dos modelos de dados utilizados pela empresa;
• Implementar pipelines de dados em frameworks de orquestração como Airflow;
• Trabalhar com tecnologias de conteinerização (Docker) e orquestração de contêineres (Kubernetes);
• Propor novas soluções tecnológicas que visem aumento de performance ou redução de complexidade e custo;

Será bem-vindo se tiver
• Conhecimentos em SQL e Python;
• Noções de ferramentas de visualização (Power BI);
• Noções de computação em nuvem e ferramentas de Big Data;
• Conhecimento em estrutura de dados;
• Inglês intermediário.

O que esperamos de você?
• Proficiência em arquitetar e gerenciar grandes volumes de dados;
• Vontade de aprender novas tecnologias, conceitos e negócios, estando pronto para mudar constantemente;
• Cuidado com os detalhes e habilidade de gerenciar demandas, sabendo priorizar e negociar com as demais áreas;
• Habilidade de negociação e gerenciamento de conflitos, conseguindo se comunicar e influenciar positivamente a tomada de decisões;
• Vontade de replicar o conhecimento, seja através de treinamentos ou de sessões 1-to-1 com outros colaboradores Buser;

### Vaga 3

REQUISITOS E QUALIFICAÇÕES

O que esperamos do (a) nosso (a) Engenheiro (a) de Dados
• Entendimento de conceitos básicos sobre ciências de dados.
• Ter experiência em desenvolvimento com Python e/ou outras linguagens de programação;
• Conhecer a linguagem SQL e bancos de dados estruturados;
• Saber utilizar Git para controlar o versionamento de seu código;
• Ter inglês técnico (que saiba se virar na Internet com documentações e fóruns).

De soft skills, procuramos alguém que:
• Se sinta motivado e desafiado diante de problemas complexos;
• Seja criativo, curioso e aberto às mudanças tecnológicas;
• Atue com leveza e bom humor para tornar a equipe sempre melhor.

Será um diferencial se você:
• Já tiver trabalhado na área da saúde;
• Tiver experiência e conhecimento em bancos não-estruturados;
• Tiver entendimento e/ou experiência com metodologia Scrum;
• Conhecer os serviços da AWS.

### Vaga 4

Experiência em desenvolvimento Java (web) ou Python e frameworks relacionados, em modelagem orientada a objetos e padrões de projeto, bancos de dados relacionais e SQL.

Vivência em levantamento e análise de requisitos (prototipação, casos de uso e diagramas uml), frameworks de gestão de projetos – (PMBOK/Agile), arquitetura de sistemas e servidores de aplicação (web, cloud, serviços, Wildfly).

Experiência com plataformas de nuvem (AWS, GCP, Azure tecnologias de front-end (HTML, CSS, JavaScript, React), banco de dados NoSQL e SearchEngines (Redis, MongoDB, ElasticSearch, Solr).

Experiência: 3 anos

Inglês intermediário.

### Vaga 5

Responsabilidades e atribuições

Como Será o Seu Dia a Dia
• Migrações de Bancos de Dados de Driven;
• Espelhamento de múltiplas fontes de dados para consolidação em uma ambiente analítico;
• Análise exploratória de bancos de dados;
• Auxiliar na migração de bancos de dados, na extração de APIs e na construção de estrutura de dados que serão consumidas pela nossa equipe de analistas e cientistas de dados.

Requisitos e qualificações

O Que Buscamos Em Você

Requisitos básicos
• Programação (Python ou equivalente);
• Banco de Dados (SQL);
• Conceitos de Data Warehousing e Estrutura de Dados.

Desejável, Mas Não Eliminatório
• Ter participado de projeto de migração de banco de dados;
• Ter conhecimento de estruturas de ERPs;
• Ter conhecimento de negócios imobiliários;
• Ter conhecimento de NoSQL.

Informações adicionais

O Que Oferecemos Aqui
• Benefícios Flexíveis;
• Educação Corporativa;
• Studio de exercícios de alta intensidade exclusivo para os funcionários;
• Parcerias com instituições de ensino;
• Plano de Saúde Nacional;
• Seguro de Vida;
• Ambientes cheios de desafios e aprendizados;
• Agilidade e autonomia;
• Salário compatível com o mercado.

### Vaga 5

Requisitos:

Requisitos:

- Modelagem de Banco de Dados Relacionais (SQL Server, Oracle ou Teradata)

- Ambiente Big Data (Hadoop, Hive, Spark, Scala, Sqoop, Linux em geral.)

- ETL (Talend, Pentaho e/ou outros)

- SQL

- Python

- Excel

- Metodologia Ágil

- Experiência na área de Telecom

- Formação Superior Completo em Exatas, Engenharia, TI, Análise e Desenvolvimento de Sistemas, etc.

- Inglês Intermediário

- Trabalho 100% Home Office

- Regime de Contratação CLT

### Vaga 6

Conhecimentos em estatística e análise de dados

MYSQL – Intermediário

PHP - Básico/Intermediário

Python - Básico/Intermediário

Habilidades Obrigatórias
• Python
• MySQL
Habilidades Desejáveis
• Node.js
• PHP
A vaga aceita trabalho remoto?

### Vaga 7

CLT + Beneficios

Remoto

Requisitos e qualificações

Vivencia com :

Big data (Hive, HBase, Spark, Pig), Python e ShellScript Linux/Unix;

Formação : Estatístico, Matematica e ou cursos co relacionados e ou TI

Desejável Pos em Big Data.


===============================================================
===============================================================
===============================================================

https://www.google.com.br/search
?q=Engenharia+de+dados+vagas
&sxsrf=AOaemvLerAD9nxdugsoAoQzIaCa54pW8WA%3A1640201216723
&ei=AHzDYcu5K6TX1sQPztS8qAk
&ved=2ahUKEwiAmpPckfj0AhUwqJUCHV7iDegQo-8GKAJ6BAgGEAc
&uact=5&oq=Engenharia+de+dados+vagas
&gs_lcp=Cgdnd3Mtd2l6EAMyBAgjECc6BwgAEEcQsAM6CwguEIAEEMcBENEDOgUIABCABDoLCAAQgAQQsQMQgwE6CAgAEIAEELEDOgsILhCxAxDHARCjAjoOCC4QgAQQsQMQxwEQ0QM6BAgAEEM6BwgAELEDEEM6CAgAELEDEIMBOgYIABAWEB5KBAhBGABKBAhGGABQ7whYliFgmiJoAXABeACAAb4BiAGnGpIBBDAuMjSYAQCgAQHIAQjAAQE
&sclient=gws-wiz
&ibp=htl;jobs#htitab=
&htivrt=jobs
&fpstate=tldetail&htilrad=-1.0
&htidocid=hDk1V8LxAgOsbTA7AAAAAA%3D%3D

### Analista Senior - Engenheiro(a) de Dados

https://g.co/kgs/4hQXix

Na EY, você terá a chance de construir uma carreira tão única quanto você, com alcance global, cultura inclusiva e tecnologia para se tornar a melhor versão de você. E nós contamos com sua voz e perspectivas únicas para ajudar a EY a se tornar ainda melhor. Junte-se a nós e construa uma experiência excepcional para você e um mundo de negócios melhor para todos.

Na área de Consulting, ajudamos organizações a se manter relevantes - agora e no futuro. Por meio dos nossos serviços de consultoria em business, tecnologia, pessoas e inovação, você poderá construir um mundo de negócios melhor apoiando clientes na transformação de seus negócios e na geração de valor de longo prazo.

Nesta oportunidade você fará:

Monitoração da execução dos processos de integração;

Criação e manutenção de bases em diferentes ambientes;

Desenvolvimento de novos estudos baseado em dados;

Responsibilities, Qualifications, Certifications - External

Suas principais responsabilidades:

Conduzir entrevistas com os consumidores para levantamento de requisitos e com os fornecedores de dados identificados para cada necessidade;

Traduzir necessidades de negócios em requisitos técnicos;

Projetar, desenvolver, implantar e oferecer suporte ao negócio através de desenvolvimento de soluções técnicas;

Desenvolver a Modelagem de Dados;

Desenvolver e acompanhar todo o processo de implantação em produção;

Desenhar os processos de Integração de Dados considerando o uso de SQL, mas também ferramentas de Big Data (Azure Synapse, Azure Data Factory, AWS Glue, AWS EMR, Hive, Hadoop, HQL);

Desenvolvimento otimização e análise de códigos SQL e rotinas ETL;

Habilidades e atributos para ter sucesso:

Ter facilidade com análise e solução de problemas e transitar muito bem entre tecnologia e negócios;

Identificar necessidades geradas pelo projeto dentro modelo analítico de dados;

Para esta posição, você deve ter:

Conhecimento avançado em Modelagem de Dados;

Conhecimento avançado em Integração de Dados;

Conhecimento avançado em Banco de Dados e linguagem SQL;

Conhecimento intermediário em levantamento de requisitos analíticos;

Conhecimento em Python;

Conhecimento em cloud Azure, GCP, AWS;

Conhecimento em Data Warehouse/Data Lake e ETL;

Conhecimento em Spark, Spark Streaming, Hive, Storm, Sqoop, Kafka, Hbase e/ou HDFS;

Também é desejável:

Inglês Avançado;

Conhecimento em Terraform, Docker e Kubernetes;

Ter vivência com metodologias ágeis: Scrum e Kanban;

O que buscamos:

Pessoas talentosas e que consigam enxergar os desafios mais difíceis de nossos clientes de todas as perspectivas. Por isso, buscamos pessoas curiosas, apaixonadas pelo que fazem e com uma variedade de habilidades.

O que oferecemos:

Oferecemos um pacote de remuneração e benefícios competitivo no segmento, através do qual você será recompensado com base no seu desempenho. Além disso, oferecemos:
• Desenvolvimento profissional com base em um extenso programa de treinamentos, coordenado pela EY University (EYU), eleita como uma das melhores universidades corporativas;
• Programa EY Badges - programa único e inovador de desenvolvimento, aprendizagem e reconhecimento, preparando os profissionais de forma teórica e prática nas competências mais relevantes da atualidade;
• Ambiente de trabalho que oferece a flexibilidade necessária para o cumprimento dos objetivos profissionais e pessoais, incentivando uma cultura de trabalho focada em resultados.

### Engenheiro Dados

https://g.co/kgs/fw6TXu

📍 HOME OFFICE

Projeto internacional de desenvolvimento de plataforma global de pagamentos

✅ REQUISITOS:
• Obrigatório espanhol para conversação
• Diferencial inglês para conversação
• Perfil autodidata
• Processamento de dados utilizando a ferramenta Apache Spark
• Bastante experiência com projetos que envolvem ETL (extração, transformação e carragamento de dados)

### Engenheiro de Dados

https://g.co/kgs/ffdgVV

Descrição: Garantir a integridade e evolução do ambiente de Big Data da empresa em Google Cloud, atuando desde a gestão do ambiente, implantação e sustentação dos pipelines de dados e algoritmos de ML.Atividades:
- Participar ativamente na evolução do ambiente de Big Data da empresa. Atividades relacionadas ao planejamento do modelo de dados, infra estrutura de banco e controle de carga de dados em ambiente cloud;
- Criar mecanismos de monitoramento de cargas de informação para garantir acuracidade dos relatórios gerenciais e análises;
- Implantar e sustentar processamento de algoritmos de Machine Learning.
- Monitorar a evolução das mudanças realizadas e propor ajustes, se necessário, de modo a garantir o atingimento dos resultados;
- Suportar o time de Big Data e analytics;Outros requisitos: - Formação Superior em cursos de TI / Engenharia;
- Domínio em SQL;
Ambiente Google Cloud e seus produtos (Compute Engine, Composer (Airflow), Dataflow, Serviços de Redes, Cloud Storage Bigquery, Pub/Sub, Cloud Run e Cloud Functions);
- Linux, Python;
- Conhecimentos em modelagem de dados relacional e não relacional;
- Experiência em banco de dados Oracle;
- Experiência em banco de dados NoSQL.
- Implantação de algoritmos de ML.
- Governança de dados.
- Conhecimento em ferramentas de automação.
- Conhecimento sobre arquiteturas containerizadas.
- Desejável experiência com o mercado de saúde / operadoras de planos, assim como seus processos e sistemas

### Engenharia de Dado

https://g.co/kgs/S5hXWB

Atividades:
• Criação de Pipeline de ingestão Dados Bacth/Realtime;
• Criação de Datasets para a área de negócio;
• Melhoria de processos complexos e com grande volume de dados;
• Tuning de processos existentes;
• Criação de processos de monitoria;
• Criação de visões gerenciais na camada SQLDW/Analysis Services para ser utilizado no PowerBI;
• Alinhar o ambiente corporativo de TI com as necessidades de negócios, padrões e melhores práticas de mercado

### Engenheiro de Dados - Risco

https://g.co/kgs/rarHzH

Estamos buscando Engenheiros de Dados (Pleno e Sênior) que tenham interesse em trabalhar com detecção de fraudes e queiram encarar conosco o desafio de fazer parte do time de tecnologia responsável pela construção da plataforma centralizada dos serviços financeiros da Stone.

Trabalhamos com Data Science e Machine Learning, atuando na criação de pipelines de processamento de dados, desenvolvimento de sistemas voltados para exploração e análise de dados em tempo real e somos a base de analytics da Conta Stone.

Nossa stack é baseada em Python e Elixir, tendo como fontes de informação dados estruturados e não-estruturados em Postgres, Kafka, BigQuery e object storages.

=> Tipo de Contratação

A contração será em regime CLT, com possibilidade de trabalho presencial nos escritórios do Rio de Janeiro e São Paulo ou 100% remoto. Sim, você pode trabalhar de qualquer lugar do Brasil :)

=> O que não pode faltar
• Experiência em SQL;
• Experiência em Airflow;
• Experiência em Spark;
• Experiência na construção de pipelines ETL/ELT;
• Experiência em ingestão de dados com BigQuery;
• Experiência em Python e/ou Scala;
• Conhecimento da Stack de Serviços de Big data/Data Lake e desenvolvimento AWS (EMR, EC2, Athena, Kinesis, S3, DynamoDB, Glue, Lambda, SageMaker).

=> O que aumentam suas chances
• Experiência em stream processing;
• Familiaridade com o conceito modelagem de dados para BI;
• Conhecimento em orquestração de containers com Kubernetes;
• Conhecimento de Terraform.

SOMOS O TIME DE BANKING DA STONE :)

Você fará parte do time de tecnologia responsável pela construção da plataforma centralizada dos serviços financeiros da Stone.

Queremos mudar a forma como lojistas gerenciam seus negócios e realizam suas operações financeiras.

Para isso, contamos com um time fora da curva e distribuído por diversas cidades do Brasil (sim, somos um time remote-first!). Além disso, não temos medo de inovar na tecnologia para entregar os melhores produtos!

Nossa stack é baseada principalmente em Elixir e Go no backend (gostamos de python também), React no frontend, serviços na AWS e apps nativos com Swift (iOS) e Kotlin (Android).
