# O que estudar para começar em Engneharia de Dados

No dia 21/06/2022 criei estudo que mostra o que um engenheiro de dados Júnior faz. E **CONSEQUENTEMENTE O QUE ESTUDAR PARA FAZER O MESMO**

## Linguagem de Programação no dia a dia

95% = Python e SQL
17% = Java e Scala

## Linguagem mais usadas (somente 1)

58% python 38% SQL

## Ferramenta de ETL

Como qualquer cargo temos a seguinte ordem

+ PBI (48%)
+ Google Data Studio (20%)
+ Tableau (20%)

## Cloud

+ AWS (59%);

+ GCP (35%); 
+ AZURE (28%)

## BD

+ PostGre 50%; 
+ Amazon S3 42; 
+ SQL SERVER 38; 
+ MYSQL (35)

**Lista de Serviços da Amazon**

+ Amazon S3 (42%)
+ Amazon Redshift (27%)
+ Amazon Athena (23%)
+ Amazon Aurora ou RDS (22%)

## ATIVIDADES ESPECIFICAS

80, 67, 56, 50, 44, 44, 31, 12

+ Desenvolvo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc. (80%)
+ Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio. (67%)
+ Modelo soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação. (56%)
+ Cuido da qualidade dos dados, metadados e dicionário de dados. (50%)
+ Realizo construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc. (44%)
+ Atuo na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc. (44%)
+ Desenvolvo/cuido da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses. (31%)
+ Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc. (12%)

## Tecnologia de ETL

+ Scripts Python (83%)
+ SQL & Stored Procedures (54%)
+ Apache Airflow (49%)

## Tecnologia de Data Quality

+ great_expectations (30%)
+ AWS Deequ (25%)
+ dbt (23%)
+ Amundsen (21%)

## Atividade que mais gasta tempo

+ Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc. (60%)
+ Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio. (26%)
+ Realizando construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc. (22%)



# CONCLUSÃO

+ Python  (Linguagem)
  + Spark (Linguagem)
  + Airflow (ETL)
  + great_expectations  (Data Quality)
+ Plataforma dbt  (Data Quality)
+ Power BI (BI)
+ SQL (Linguagem)
+ BD
  + Postre SQL (BD)
  + SQL Server (BD)
  + Mysql (BD)
+ AWS
  + S3 (BD)
  + Redshift (BD)
  + Athena (BD)
  + Aurora ou RDS (BD)
  + AWS Dequ (Data Quality)
  + Glue (ETL)

Que atividades aprender a fazer

+ Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc. (60%)
+ Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio. (26%)
+ Realizando construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc. (22%)
